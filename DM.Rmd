---
title: "Modèle linéaire généralisé et Choix de modèles"
author: "Olga SILVA"

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

> Objectif

L'objectif de ce projet est de proposer et valider un modèle pour expliquer la présence de pluie le lendemain. Puis proposer une prédiction binaire pour les lendemains des journées incluses dans le fichier de test.

Le fichier à utiliser pour entraîner le modèle (meteo.train.csv) contient des données sur les conditions météorologiques à Bâle (Suisse).

Chaque ligne correspond à un jour entre 2010 et 2018. Les colonnes correspondent aux valeurs moyenne, minimale et maximale sur la journée de : 

* Température (°C)
* Humidité relative (pourcentage)
* Pression (hPa)
* Nébulosité (pourcentage)
* Nébulosité forte, moyenne et faible
* Vitesse (en km/h) et direction (en degrés) du vent à 10 m d'altitude, 80 m d'altitude, et à l'altitude où la pression vaut 900 hPa
* Rafales de vent à 10 m

Ainsi qu'aux valeurs totales sur la journée de :

* Précipitations (mm)
* Neige (cm)
* Minutes d'ensoleillement
* Rayonnement solaire (W/m2)

> Librairies

D'abord je charge les packages que je vais utiliser lors du projet. 

```{r libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(caret)
library(gmodels)
library(lattice)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(RColorBrewer)
library(e1071)
library(MASS)
library(leaps)
library(car)

```

## Lecture et première analyse des données

Pour commencer, je vais lire les données et voir les caractéristiques du dataframe. Cela me permettra de comprendre la structure des données. 

```{r reading_data}
meteo <- read.csv('meteo.train.csv')
dim(meteo)
str(meteo)
sum(is.na(meteo))
```

Suite à ces résultats je peux dire que :

1. C'est un dataframe avec `r nrow(meteo)` observations et `r ncol(meteo)` variables; dont "X" qui correspond à l'ID et "pluie.demain" la variable à prédire, il reste alors 45 variables explicatives.

2. Les variables sont toutes numériques, sauf la variable à prédire "pluie.demain", qui est une variable logique.

3. Le dataframe est complet et bien rempli, car il n'y a pas des valeurs NA. Donc, je n'ai pas de nettoyage ou de préparation à réaliser.

## Connaître les données

Je vais faire maintenant un peu d'exploration pour voir le comportement des données. 

Les données vont de l'année `r min(meteo$Year)` au `r max(meteo$Year)`. Sachant que pour ces deux années extrêmes nous n'avons pas les données pour les 12 mois. Pour 2010, les données commencent en `r min(subset(meteo, Year == "2010")[,"Month"])` et pour 2018 elles finissent en `r max(subset(meteo, Year == "2018")[,"Month"])`

Tout d'abord je voudrais savoir si les données sont bien équilibrées, c'est à dire s'il y a autant des jours avec et sans pluie, pour bien entraîner le modèle. Et s'il existe une relation simple à voir entre l'année et la pluie.
```{r knowing_data}

table(meteo$pluie.demain)
table(meteo$Year,meteo$pluie.demain)

```

On voit bien clairement que les données sont équilibrées (625 FALSE et 619 TRUE)

Par rapport à l'année, on voit des années plus sèches comme le 2011 et le 2015, et des années plus humides comme le 2012. 

Avant de continuer, je vais renommer les variables pour faciliter la lecture et manipulation des données, car les noms d'origine semblent très longs. 

```{r rename}

meteo <- meteo %>% rename(Temp_moy = Temperature.daily.mean..2.m.above.gnd., 
                          Humidite_moy = Relative.Humidity.daily.mean..2.m.above.gnd.,
                          Pression_moy = Mean.Sea.Level.Pressure.daily.mean..MSL.,
                          Precipitations_jour = Total.Precipitation.daily.sum..sfc.,
                          Neige_jour = Snowfall.amount.raw.daily.sum..sfc.,
                          Nebulosite_moy = Total.Cloud.Cover.daily.mean..sfc.,
                          Nebulosite_high = High.Cloud.Cover.daily.mean..high.cld.lay.,
                          Nebulosite_medium = Medium.Cloud.Cover.daily.mean..mid.cld.lay.,
                          Nebulosite_low = Low.Cloud.Cover.daily.mean..low.cld.lay.,
                          Sunshine_jour = Sunshine.Duration.daily.sum..sfc.,
                          Radiation_jour = Shortwave.Radiation.daily.sum..sfc.,
                          Vent_vitesse_10m = Wind.Speed.daily.mean..10.m.above.gnd.,      
                          Vent_dir_10m = Wind.Direction.daily.mean..10.m.above.gnd.,
                          Vent_vitesse_80m = Wind.Speed.daily.mean..80.m.above.gnd.,
                          Vent_dir_80m = Wind.Direction.daily.mean..80.m.above.gnd.,
                          Vent_vitesse_900hpa = Wind.Speed.daily.mean..900.mb.,
                          Vent_dir_900hpa = Wind.Direction.daily.mean..900.mb.,
                          Rafales_moy = Wind.Gust.daily.mean..sfc.,
                          Temp_max_2m = Temperature.daily.max..2.m.above.gnd. ,
                          Temp_min_2m = Temperature.daily.min..2.m.above.gnd. ,
                          Humidite_max = Relative.Humidity.daily.max..2.m.above.gnd. ,
                          Humidite_min = Relative.Humidity.daily.min..2.m.above.gnd. ,
                          Pression_max = Mean.Sea.Level.Pressure.daily.max..MSL.,
                          Pression_min = Mean.Sea.Level.Pressure.daily.min..MSL. ,
                          Nebulosite_total_max = Total.Cloud.Cover.daily.max..sfc.,
                          Nebulosite_total_min = Total.Cloud.Cover.daily.min..sfc.,
                          Nebulos_high_max = High.Cloud.Cover.daily.max..high.cld.lay.,
                          Nebulos_high_min = High.Cloud.Cover.daily.min..high.cld.lay.,
                          Nebulos_medium_max = Medium.Cloud.Cover.daily.max..mid.cld.lay.,
                          Nebulos_medium_min = Medium.Cloud.Cover.daily.min..mid.cld.lay.,
                          Nebulos_low_max = Low.Cloud.Cover.daily.max..low.cld.lay.,
                          Nebulos_low_min = Low.Cloud.Cover.daily.min..low.cld.lay.,
                          Vent_vitesse_10m_max = Wind.Speed.daily.max..10.m.above.gnd.,
                          Vent_vitesse_10m_min = Wind.Speed.daily.min..10.m.above.gnd.,
                          Vent_vitesse_80m_max = Wind.Speed.daily.max..80.m.above.gnd.,
                          Vent_vitesse_80m_min = Wind.Speed.daily.min..80.m.above.gnd.,
                          Vent_vitesse_900hpa_max = Wind.Speed.daily.max..900.mb.,
                          Vent_vitesse_900hpa_min = Wind.Speed.daily.min..900.mb.,
                          Rafales_max = Wind.Gust.daily.max..sfc.,
                          Rafales_min = Wind.Gust.daily.min..sfc.)


```

> Analyse graphique

Selon météo France, 4 paramètres sont très importants pour les prévisions météorologiques : la température, le vent, l’humidité et la pression. 

Regardons maintenant quelques graphiques pour mieux voir la relation entre la pluie le lendemain et quelques variables explicatives. 

```{r graphics}

ggplot(data = meteo, aes(Year)) + geom_bar(fill = "blue")+labs(title ="Données par année", x = "Année") 
ggplot(data = meteo, aes(Year,fill=pluie.demain)) + geom_bar() +labs(title ="Pluie par année", x = "Année") 

temp <-ggplot(data = meteo, aes(pluie.demain,Temp_moy)) + geom_boxplot(fill = "#E6AB02")+theme_minimal()+labs(x = "Pluie Demain", y = "Température Moyenne") 

hum <- ggplot(data = meteo, aes(pluie.demain,Humidite_moy)) + geom_boxplot(fill = "#66A61E")+theme_minimal()+ labs(x = "Pluie Demain", y = "Humidité Moyenne") 

press<-ggplot(data=meteo, aes(pluie.demain,Pression_moy)) + geom_boxplot(fill="#1B9E77")+theme_minimal()+ labs(x = "Pluie Demain", y = "Pression Moyenne") 

neb<-ggplot(data=meteo, aes(pluie.demain,Nebulosite_moy)) + geom_boxplot(fill="#D95F02")+theme_minimal()+ labs(x = "Pluie Demain", y = "Nebulosité Moyenne") 

suns<-ggplot(data=meteo, aes(pluie.demain,Sunshine_jour)) + geom_boxplot(fill="#E7298A")+theme_minimal()+ labs(x = "Pluie Demain", y = "Minutes de soleil") 

radiat<-ggplot(data=meteo, aes(pluie.demain,Radiation_jour)) + geom_boxplot(fill="#A6CEE3")+theme_minimal()+ labs(x = "Pluie Demain", y = "Radiation par jour") 

prec<-ggplot(data=meteo, aes(pluie.demain,Precipitations_jour)) + geom_boxplot(fill="#7570B3")+theme_minimal()+ labs(x = "Pluie Demain", y = "Précipitations par jour") 

vvent<-ggplot(data=meteo, aes(pluie.demain,Vent_vitesse_900hpa)) + geom_boxplot(fill="#A6761D")+theme_minimal()+ labs(x = "Pluie Demain", y = "Vitesse du vent")

dvent<-ggplot(data=meteo, aes(pluie.demain,Vent_dir_900hpa)) + geom_boxplot(fill="#B2182B")+theme_minimal()+ labs(x = "Pluie Demain", y = "Direction du vent")


grid.arrange(temp, hum, press,neb, prec, suns, radiat, vvent, dvent, ncol=3, nrow = 3)
```

Grâce à ces graphiques je peux dire que:

* Cela confirme les informations sur les années plus secs et plus humides
* Il semblerait qu’il existe une relation forte entre pluie vs : la pression, la nébulosité, les minutes de soleil et la direction du vent. En sachant que peut-être ces variables sont corrélées. Par exemple, les jours pluvieux sont d’habitude nuageux avec moins de soleil. 

Regardons ces dernières variables plus en détail, par rapport à la pluie le lendemain. 

```{r graphics_suite}

ggplot(data = meteo) + geom_histogram(mapping = aes(x = Pression_moy,fill=pluie.demain),bins=40) + facet_wrap(~ pluie.demain, nrow = 2) + theme(legend.position = "none")+ scale_fill_brewer(palette = "Set1")

ggplot(data = meteo) + geom_histogram(mapping = aes(x = Nebulosite_moy,fill=pluie.demain),bins=40) + facet_wrap(~ pluie.demain, nrow = 2) + theme(legend.position = "none") + scale_fill_brewer(palette = "Set2")

ggplot(data = meteo) + geom_histogram(mapping = aes(x = Sunshine_jour,fill=pluie.demain),bins=40) + facet_wrap(~ pluie.demain, nrow = 2) + theme(legend.position = "none") + scale_fill_brewer(palette = "Paired")

ggplot(data = meteo) + geom_histogram(mapping = aes(x = Vent_dir_900hpa,fill=pluie.demain),bins=40) + facet_wrap(~ pluie.demain, nrow = 2) + theme(legend.position = "none") + scale_fill_brewer(palette = "Accent")

ggplot(data = meteo) + geom_histogram(mapping = aes(x = Temp_moy,fill=pluie.demain),bins=40) + facet_wrap(~ pluie.demain, nrow = 2) + theme(legend.position = "none")+ scale_fill_brewer(palette = "Spectral")

```

**PRESSION**

Le graphique nous montre que quand la pression est plus élevée, il y a moins de pluie et quand la pression est plus basse, il y a plus de pluie le lendemain. Cela est cohérent avec des informations météorologiques de basse et haute pression. 

**NEBULOSITE ET ENSOLEILLEMENT**

Sans surprise, plus de nébulosité semble indiquer pluie le lendemain. Et plus d'ensoleillement moins de risque de pluie. 

**DIRECTION DU VENT**

Pour la direction du vent où la pression vaut 900 hPa, il semblerait que pour des degrés plus bas il y a moins risque de pluie que pour les degrés plus élevés. 

**TEMPERATURE**

Suivant les idées de météo France, je fais un graphique pour les températures, mais les conclusions sont moins évidentes.  Pour des plus fortes températures il semblerait qu’il y a plus de risque de pluie le lendemain.

**MOIS**

Je voudrais aussi savoir si le mois est une donnée importante de prédiction, pour cela, voici un graphique qui compte les jours de pluie et de non pluie pour chaque mois.

```{r graphics_month}

ggplot(data = meteo) + geom_bar(mapping = aes(x = as.factor(Month),fill=pluie.demain))+ facet_wrap(~ pluie.demain, ncol = 2) + scale_fill_brewer(palette = "Pastel1") + theme(legend.position = "none") + labs(x = "Mois")

```

En ce qui concerne les mois, on observe que les plus humides sont janvier, mai et juin. Les plus secs sont mars et octobre. 

> CORRELATION

Regardons maintenant la corrélation entre les variables. Même si j’imagine que nous ne ferons pas un modèle avec toutes les variables explicatives, cela me permettra de voir lesquels sont très corrélées entre elles. Car une des hypothèses de la régression logistique est que les variables devraient être indépendants entre elles, c’est à dire le modèle doit avoir une multicolinéarité basse ou nulle.


```{r correlation}

numeric_vars <- colnames(meteo)
numeric_vars <- setdiff(numeric_vars, c("pluie.demain","X","Hour","Day","Minute","Year","Month"))
numeric_vars_mat <- as.matrix(meteo[, numeric_vars, drop=FALSE])
corrplot(cor(numeric_vars_mat),type = "upper",method = "circle",order = "hclust",tl.cex = 0.5)

```

Nous pouvons observer une corrélation très forte pour les variables de vent (vitesse, direction, rafales) entre elles-mêmes, et une corrélation négative entre un ciel nuageux et les minutes de soleil et l’ensoleillement. Pareil pour l’humidité et ces deux dernières.


## Validation croisée & modelisation

Avant de commencer à construire le modèle, je vais diviser les données en deux parties : entraînement et test. Cela me permettra  de prédire l'efficacité du modèle avant de l'utiliser sur les données inconnues de test définitives. 

Il y a plusieurs méthodes pour le faire disponibles sur R, je vais utiliser le "holdout method", un de plus utilisés. Avec 70% des données à laisser pour l'entraînement et 30% pour la validation. 

Ensuite je vais faire une régression logistique, car la variable réponse est binaire, avec TRUE ou FALSE comme possibilités. 

```{r partition}
set.seed(123) ## pour pouvoir le reproduire

meteo2 <- meteo[c(-1,-4,-5,-6)] # sortir des variables peu intéressants pour construire le modèle
trainIndex = createDataPartition(meteo2$pluie.demain,p=0.7, list=FALSE,times=1)
 
train = meteo2[trainIndex,]
test = meteo2[-trainIndex,]

```

Après la création de la partition, je vérifie que la partition est bien équilibrée : 

```{r partition_verif}

table(train$pluie.demain)
table(test$pluie.demain)

```


**MODELE 1**

Pour pouvoir choisir le modèle je vais faire d'abord un modèle complet avec toutes les variables, et ensuite utiliser la méthode pas à pas, avec la fonction step, direction "backward", pour sélectionner le meilleur modèle (selon le critère AIC). La donnée AIC (Akaike information criterion) est une technique pour estimer la probabilité d'un modèle pour prédire les valeurs futures. Un bon modèle est celui qui a un AIC minimum par rapport aux autres modèles. 

```{r model}
set.seed(123) ## pour pouvoir le reproduire

meteo2 <- meteo[c(-1,-4,-5,-6)] # sortir des variables peu intéressants pour construire le modèle
trainIndex = createDataPartition(meteo2$pluie.demain,p=0.7, list=FALSE,times=1)
 
train = meteo2[trainIndex,]
test = meteo2[-trainIndex,]

full.model <- glm(pluie.demain ~., data = train, family = binomial(logit))

step.model <- step(full.model, direction = "backward", trace = FALSE)
summary(step.model)

```

Selon cette méthodologue, le meilleur modèle est le suivant : 

```{r AIC}

step.model$formula
step.model$aic

```


La différence entre la déviance nulle (quand le modèle a uniquement l’intercept) et la déviance résiduelle (avec toutes les variables), indique que le modèle est un bon estimateur.

La table de coefficients donne les valeurs estimées des betas, pour le modèle de régression logistique. Les coefficients de nébulosité et vitesse du vent sont positifs. Cela est cohérent avec les résultats des graphiques faites dans la section précédente.

Par contre c’est un modèle complexe, avec trop de prédicteurs. Cela est peut-être dû au fait que je démarre avec toutes les variables.
Je vais vérifier la multicolinéarité entre les variables du modèle, c’est à dire si j’ai une redondance entre mes variables de prédiction. Cela a dû au fait que la régression logistique a besoin de peu ou pas du tout de multicolinéarité entre les variables indépendantes. Elles ne doivent pas avoir une corrélation trop importante entre elles.

Pour le faire je vais utiliser la fonction VIF, de la librairie CAR, car elle permet de détecter la multicolinéarité pour les modèles de régression et elle est facile à interpréter ( pour une valeur élevée : une multicolinéarité élevée)


```{r VIF}
vif(step.model)

```

Je vois que j'ai plusieurs variables avec un VIF bien plus grand que 5 (Temp_moy, Vent_vitesse_80m, Temp_max_2m, Temp_min_2m, Nebulosite_total_min, Nebulos_low_min et Vent_vitesse_10m_max). Cela veut dire que l'information apporté par ces variables est redondant avec l'information d'autres variables présents dans le modèle, et qu'un modèle plus simple pourra être envisagé. 

Comme la régression logistique n’a pas comme hypothèse que les erreurs doivent avoir une distribution gaussienne et l’homoscédasticité n’est pas requise, je ne vais pas vérifier ces deux sujets. 

**MODELE 2**

Je vais construire un nouveau modèle avec la même méthodologie step mais avec la direction forward pour voir si j'arrive à avoir un modèle avec moins de variables explicatives, en démarrant avec le modèle le plus simple possible. 

```{r model2}

basic.model <- glm(pluie.demain ~1, data = train, family = binomial(logit))
step2.model <- stepAIC(basic.model, direction = "forward", scope = formula(full.model),trace = FALSE)
summary(step2.model)

```

Selon ces résultats il nous propose le modèle suivant : 

```{r aic2}

step2.model$formula
step2.model$aic

```

Les données sélectionnées sont cohérentes avec les relations trouves dans la section "connaître nos données", entre la pluie le lendemain et la nébulosité, pression et vent.

L’AIC est plus élevé que pour le modèle précèdent, mais sa simplicité peut être un atout pour éviter l’overfitting. 


Je vérifie aussi la multicolinéarité pour le modèle 2 :


```{r VIF2}

vif(step2.model)

```

Voici une bonne nouvelle, les variables n’ont pas une multicolinéarité importante, je vais garder le modèle pour comparer ses propriétés de prédiction. 

**MODELE 3**

Comme dernière méthode, je vais utiliser la fonction regsubsets et la méthode exhaustive, en utilisant comme critère de sélection le BIC (Schwartz’ Bayesian Information Criterion). J’ajoute aussi le paramètre d’avoir maxi 12 variables, car cela reviendra à avoir le modèle 1. 

```{r model3}

reg.model=regsubsets(pluie.demain ~.,method="exhaustive",nvmax = 12, data=train)
plot(reg.model, scale = "bic")
reg.summary = summary(reg.model)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "bic")

```

Le premier graphique affiche les valeurs BIC pour chaque modèle (en ligne). Les carrés noirs indiquent les variables inclus dans le modèle. Selon celui-ci, 3 modèles ont le BIC le plus faible (-180) : 

1. pluie.demain ~ Intercept + Vent_vitesse_900hpa + Pression_min + Nebulos_medium_max
2. pluie.demain ~ Intercept + Vent_vitesse_900hpa + Pression_min + Nebulos_medium_max + Nebulosite_medium
3. pluie.demain ~ Intercept + Vent_vitesse_900hpa + Pression_min + Nebulos_medium_max + Nebulosite_total_min + Nebulos_low_min

Le dernière graphique, montre le nombre de variables où le BIC trouve son minimum : `r which.min(reg.summary$bic)` variables, avec un BIC de `r min(reg.summary$bic)`.`

Je vais garder alors le modèle 1.

```{r VIF3}

reg.model2 <- glm(pluie.demain ~ Vent_dir_900hpa + Pression_min + Nebulos_medium_max, data = train, family = binomial(logit))
vif(reg.model2)

```

Un modèle très similaire au modèle 2, avec aussi des valeurs VIF bas. 

## Sélection du modèle

Je vais comparer les prédictions des trois modèles sur les données test avant de choisir le modèle définitif.

Comme les modèles donnent des résultats entre 0 et 1, (0: pas de pluie le lendemain, 1 : pluie le lendemain), il faut établir un seuil à partir duquel la réponse est vrai ou faux.  

**Seuil de 0.5**

Je vais faire ma première prédiction avec un seuil à 0.5. 

Afin de visualiser les résultats, je vais les afficher comme une matrice de confusion, pour voir les cas où le modèle a prédit correctement et les cas où le modèle a fait des erreurs.

En ligne, nous allons trouver les données prédites et en colonne les données réelles de validation. 

```{r Prédiction}
glm.pred1 <- predict(step.model, newdata = test, type = "response")
table(glm.pred1 > 0.5, test$pluie.demain)

glm.pred2 <- predict(step2.model, newdata = test, type = "response")
table(glm.pred2 > 0.5, test$pluie.demain)

glm.pred3 <- predict(reg.model2, newdata = test, type = "response")
table(glm.pred3 > 0.5, test$pluie.demain)

```

La classification des trois modèles est très proche, par exemple pour les "vrais positifs", le modèle 1 a 149, le modèle 2 a 156 et le modèle 3 a 155. Les vrais positifs sont les données identifiées comme positives par le modèle et qui sont positives en réalité, donc, correctes.

Pour les trues négatifs, le modèle 1 a 111, le modèle 2 104 et le modèle 3 103. 

Je vais maintenant regarder les erreurs des trois modèles 

```{r error_0.5}
##classification rate

mean(abs(glm.pred1 - test$pluie.demain), na.rm = T)
mean(abs(glm.pred2 - test$pluie.demain), na.rm = T)
mean(abs(glm.pred3 - test$pluie.demain), na.rm = T)
```

40% d'erreurs pour les 3 modèles. Je vais modifier le seuil pour faire baisser l'erreur. 

**Seuil de 0.7**

Voici les matrices de confusion pour le seuil à 0.7 : 

```{r Prédiction2}
table(glm.pred1 > 0.7, test$pluie.demain)
table(glm.pred2 > 0.7, test$pluie.demain)
table(glm.pred3 > 0.7, test$pluie.demain)

```

Calcul de l'erreur pour le seuil de 0.7

```{r error_0.7}

mean(abs((glm.pred1 > 0.7) - test$pluie.demain), na.rm = T)
mean(abs((glm.pred2 > 0.7) - test$pluie.demain), na.rm = T)
mean(abs((glm.pred3 > 0.7) - test$pluie.demain), na.rm = T)
```

Je vois que changer le seuil change le pourcentage d'erreur, je vais maintenant trouver le seuil optimal pour chaque modèle. Comme je n'ai pas un type d'erreur à privilégier, car nous n'avons pas un enjeu spécifique, comme par exemple pour la détection des malades de cancer, je vais optimiser les deux erreurs, en utilisant la fonction optimalcutoff et l'option d'optimiser par la misclassification.  La classification erronée est la proportion d'observations qui ne sont pas prédites correctement.


```{r optimal}

library(InformationValue)
optCutOff1 <- optimalCutoff(test$pluie.demain, glm.pred1, optimiseFor = "misclasserror",returnDiagnostics = TRUE)
optCutOff2 <- optimalCutoff(test$pluie.demain, glm.pred2, optimiseFor = "misclasserror",returnDiagnostics = TRUE)
optCutOff3 <- optimalCutoff(test$pluie.demain, glm.pred3, optimiseFor = "misclasserror",returnDiagnostics = TRUE)
```


> Pour le modèle 1:

Voici les résultats pour le modèle 1 de précision, recall, erreur de classification et la matrice de confusion.

Ces indicateurs me permettront de comparer les modèles entre eux et choisir le meilleur.
**Precision =** TP /(TP + FP). Il montre quand le modèle prédit la pluie, combien de fois c'est correct.     
**Sensitivity/Recall =** TP/(TP + FN). Quand il pleut, combien de fois le modèle arrive à le prédire. 

Ces deux indicateurs sont très liés car quand nous augmentons le recall, nous diminuons la précision ou la capacite du modèle d'identifier uniquement les données pertinentes. Il faut comparer et équilibrer le coût de ne pas détecter les positifs vs le coût d'augmenter les fausses alarmes.


```{r results1}

precision(actuals=test$pluie.demain, predictedScores=glm.pred1)
optCutOff1$TPR
mean(abs((glm.pred1 > optCutOff1$optimalCutoff) - test$pluie.demain), na.rm = T)
confusionMatrix(test$pluie.demain, glm.pred1, threshold = optCutOff1$optimalCutoff)
```


> Pour le modèle 2:

```{r results2}

precision(actuals=test$pluie.demain, predictedScores=glm.pred2)
optCutOff2$TPR
mean(abs((glm.pred2 > optCutOff2$optimalCutoff) - test$pluie.demain), na.rm = T)
confusionMatrix(test$pluie.demain, glm.pred2, threshold = optCutOff2$optimalCutoff)
```

> Pour le modèle 3:


```{r results3}

precision(actuals=test$pluie.demain, predictedScores=glm.pred3)
optCutOff3$TPR
mean(abs((glm.pred3 > optCutOff3$optimalCutoff) - test$pluie.demain), na.rm = T)
confusionMatrix(test$pluie.demain, glm.pred3, threshold = optCutOff3$optimalCutoff)
```

## CHOIX ET PREDICTION FINAL

Selon les résultats, le meilleur modèle semble être le 3, même si le 2 reste assez proche. Je vais faire les predictions et les garder en format csv.


```{r final}

final_test <- read.csv('meteo.test.csv')
## change the names
final_test <- final_test %>% rename(Temp_moy = Temperature.daily.mean..2.m.above.gnd., 
                          Humidite_moy = Relative.Humidity.daily.mean..2.m.above.gnd.,
                          Pression_moy = Mean.Sea.Level.Pressure.daily.mean..MSL.,
                          Precipitations_jour = Total.Precipitation.daily.sum..sfc.,
                          Neige_jour = Snowfall.amount.raw.daily.sum..sfc.,
                          Nebulosite_moy = Total.Cloud.Cover.daily.mean..sfc.,
                          Nebulosite_high = High.Cloud.Cover.daily.mean..high.cld.lay.,
                          Nebulosite_medium = Medium.Cloud.Cover.daily.mean..mid.cld.lay.,
                          Nebulosite_low = Low.Cloud.Cover.daily.mean..low.cld.lay.,
                          Sunshine_jour = Sunshine.Duration.daily.sum..sfc.,
                          Radiation_jour = Shortwave.Radiation.daily.sum..sfc.,
                          Vent_vitesse_10m = Wind.Speed.daily.mean..10.m.above.gnd.,      
                          Vent_dir_10m = Wind.Direction.daily.mean..10.m.above.gnd.,
                          Vent_vitesse_80m = Wind.Speed.daily.mean..80.m.above.gnd.,
                          Vent_dir_80m = Wind.Direction.daily.mean..80.m.above.gnd.,
                          Vent_vitesse_900hpa = Wind.Speed.daily.mean..900.mb.,
                          Vent_dir_900hpa = Wind.Direction.daily.mean..900.mb.,
                          Rafales_moy = Wind.Gust.daily.mean..sfc.,
                          Temp_max_2m = Temperature.daily.max..2.m.above.gnd. ,
                          Temp_min_2m = Temperature.daily.min..2.m.above.gnd. ,
                          Humidite_max = Relative.Humidity.daily.max..2.m.above.gnd. ,
                          Humidite_min = Relative.Humidity.daily.min..2.m.above.gnd. ,
                          Pression_max = Mean.Sea.Level.Pressure.daily.max..MSL.,
                          Pression_min = Mean.Sea.Level.Pressure.daily.min..MSL. ,
                          Nebulosite_total_max = Total.Cloud.Cover.daily.max..sfc.,
                          Nebulosite_total_min = Total.Cloud.Cover.daily.min..sfc.,
                          Nebulos_high_max = High.Cloud.Cover.daily.max..high.cld.lay.,
                          Nebulos_high_min = High.Cloud.Cover.daily.min..high.cld.lay.,
                          Nebulos_medium_max = Medium.Cloud.Cover.daily.max..mid.cld.lay.,
                          Nebulos_medium_min = Medium.Cloud.Cover.daily.min..mid.cld.lay.,
                          Nebulos_low_max = Low.Cloud.Cover.daily.max..low.cld.lay.,
                          Nebulos_low_min = Low.Cloud.Cover.daily.min..low.cld.lay.,
                          Vent_vitesse_10m_max = Wind.Speed.daily.max..10.m.above.gnd.,
                          Vent_vitesse_10m_min = Wind.Speed.daily.min..10.m.above.gnd.,
                          Vent_vitesse_80m_max = Wind.Speed.daily.max..80.m.above.gnd.,
                          Vent_vitesse_80m_min = Wind.Speed.daily.min..80.m.above.gnd.,
                          Vent_vitesse_900hpa_max = Wind.Speed.daily.max..900.mb.,
                          Vent_vitesse_900hpa_min = Wind.Speed.daily.min..900.mb.,
                          Rafales_max = Wind.Gust.daily.max..sfc.,
                          Rafales_min = Wind.Gust.daily.min..sfc.)

glm.final_test <- predict(reg.model2, newdata = final_test, type = "response")


glm.final = ifelse(glm.final_test > optCutOff3$optimalCutoff, 1, 0)

write.csv(glm.final,'meteo.test_final.csv')

```


## Conclusions

J'ai testé plusieurs méthodes vues en cours pour pouvoir faire une prédiction en faisant une régression logistique, car les données à prédire sont logiques (TRUE et FALSE). 

Les méthodes utilisées sont : 

* Step en partant du modèle complet et en utilisant la méthode backwards, en optimisant l'AIC
* Step en partant du modèle simple et en utilisant la méthode forward, en optimisant l'AIC
* Regsubsets et la méthode exhaustive, en optimisant le BIC

Pour sélectionner le modèle j'ai vérifié la prédiction sur le 30% des données de train, et j'ai comparé le recall, la précision et l'erreur de classification. 

À la suite de cela, j'ai sélectionné le modèle trouve avec regsubsets, même si les résultats sont assez proches, car j'ai préféré privilégier un modèle simple avec une corrélation basse entre les variables explicatives. J'aurais pu comparer le temps machine de chaque méthode pour affiner ma sélection, mais comme le dataframe est petit, je n'ai pas voulu tenir compte de ce critère. 

La prédiction finale est enregistrée en csv et les valeurs ont été arrondies selon l'optimal cutoff trouvé lors de l'entraînement des données.




